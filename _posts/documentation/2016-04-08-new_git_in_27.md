---
layout: post
title: Git work flows in the upcoming 2.7 release
---

The upcoming Open Build Service (OBS) 2.7 release will deliver significant 
changes to the way we are dealing with git sources for builds.

OBS was designed for Linux distribution creation, not software development. In
your typical distribution, in the creation work flow, you get a new upstream 
release in the form of a tar ball from time to time, and you add patches on top of 
that for local fixes. Nowadays the OBS is also used for development of a single 
software project. That work flow has completely different requirements: for 
every commit the developer wants a new build.  Developers want continuous builds.

## The problem
In the past a build on the OBS would fetch the git repository and create a tar
ball every time. Even if you only changed on single bit, the complete repository
would be fetched and a new tar ball would be generated and stored. As you can
imagine this was not efficient at all.

## The Solution
In OBS 2.7 we have introduced a [new format](#algorithm-details) for incremental 
storage of git commits. This has a number of advantages:

1. We can store the cloned source archive in an efficient way which means
   OBS instances will use significantly less disk space for builds with git
   repositories as sources.
2. The git checkout becomes available as directory for the build. You have the
   chance to implement a variety of source services that interact with the
   checkout.
3. The git checkout becomes available as directory in your *osc* checkout.
   You can do your git work directly from the *osc* checkout and test them with
   a local build.

### An example
A practical example may help to explain how this works. [an example based on a package](https://build.opensuse.org/package/show/hardware:RC-Model:Unstable/qgroundcontrol)
This example uses [qgroundcontrol](http://qgroundcontrol.io/), a drone control
application.

First, create the package container as usual:

{% highlight bash %}
osc meta pkg -e hardware:RC-Model:Unstable/qgroundcontrol
{% endhighlight %}
<br />
then tell the OBS where the git repository is via:

{% highlight bash %}
osc add git://github.com/mavlink/qgroundcontrol.git
{% endhighlight %}
<br />
which will create a source service (_service) file like this:

{% highlight xml %}
<services>
  <service name="obs_scm">
    <param name="url">git://github.com/mavlink/qgroundcontrol.git</param>
    <param name="scm">git</param>
  </service>
  <service mode="buildtime" name="tar" />
  <service mode="buildtime" name="recompress">
    <param name="file">*.tar</param>
    <param name="compression">xz</param>
  </service>
  <service mode="buildtime" name="set_version" />
</services>
{% endhighlight %}
<br />
and finally, add a RPM spec file (copied from the stable package in this case):

{% highlight bash %}
osc cat hardware:RC-Model qgroundcontrol qgroundcontrol.spec > qgroundcontrol.spec
{% endhighlight %}
<br />
When committing this, the OBS fetches the checkout, builds a tar ball and runs
the build. If you have been using source services for git repositories before
nothing really changed in ***your*** work flow yet, right? Now comes the interesting
part: Working with git in your *osc* checkout.

### Working with *git* in your *osc* checkout
Let's say you want to fix something in your git repository _AND_ you want to
make sure it still builds.

First check out the package with:

{% highlight bash %}
osc co hardware:RC-Model:Unstable/qgroundcontrol
{% endhighlight %}
<br />
create the git checkout with:

{% highlight bash %}
osc service run
{% endhighlight %}
<br />
An unversioned directory called "qgroundcontrol" will be created.
You can go inside and modify any file and start a local build.

{% highlight bash %}
osc build
{% endhighlight %}
<br />
The source service will run again, fetch changes from the git repository (incremental
changes, not the entire repository), and then apply your local changes on top
of it.

You can simply commit your local changes to the package, or you can of course push
them using git. How awesome is that!?

#### Some more tricks
The obs_scm service also allows you to fetch files directly from the checkout.
For instance you could maintain your build description (e.g. RPM spec file)
in git and let OBS use it by using the "extract" parameter for the service.

> <span style="color: red">Warning</span>: We have not yet released the new tools. If you want to try this now please
> add the repository for your distribution from the openSUSE:Tools project and
> install osc, build and obs-service-tar_scm from there onto your workstation.
> You have to do the same for your OBS project, it has to build against the
> openSUSE:Tools project to get the tools for creating the tar ball.
>
> These steps won't be necessary anymore when we release OBS 2.7.

#### Algorithm details
As most commits only change some lines in a few files, we want to store only
those changes. The OBS is pretty file-centric, so we want to keep the tar balls
stored as single files. But we want to only store the deltas between those
files, like the xdelta or rsync tools do. Delta algorithms work by finding
common blocks in files. Unfortunately this means that the files cannot be
compressed, as the compression result is near to random bytes. In the end we
came up with our own algorithm for the very simplistic cpio new format.

As an example, consider that we have a file:

{% highlight bash %}
The quick brown hare jumps over the lazy dog ...
{% endhighlight %}
<br>
and we want to change it to:

{% highlight bash %}
The quick brown fox jumps over the lazy dog ...
{% endhighlight %}
<br>
We split one of the files into blocks of fixed size:

{% highlight bash %}
|The quic|k brown |hare jum|ps over |the lazy| dog ...|
{% endhighlight %}
<br />
We hash the block contents with a rolling checksum, so that we can
look them up in a fast way.
Then we go through the other file and try to find those blocks:
{% highlight bash %}
|The quic|
{% endhighlight %}
<br />
Ah, nice, found a hit. Extend it in both directions as long as the
content is the same:
{% highlight bash %}
|The quick brown |
{% endhighlight %}
<br />
So we encode "take 16 bytes from offset 0". Then continue searching:
{% highlight bash %}
|fox jump|
{% endhighlight %}
<br />
No match. Roll in one byte:

{% highlight bash %}
|ox jumps|
{% endhighlight %}
<br />
No match. Roll in one byte:

{% highlight bash %}
|x jumps |
{% endhighlight %}
<br />
... roll roll roll...

{% highlight bash %}
|umps ove|
|mps over|
|ps over |
{% endhighlight %}
<br />
A hit! Extend in both directions:
{% highlight bash %}
| jumps over the lazy dog !!!|
{% endhighlight %}
<br />
The still rolled out bytes are:
{% highlight bash %}
|fox|
{% endhighlight %}
<br />
So we encode both "take the following 3 bytes: 'fox'" and "take 28 byes from offset 20".
Now we're done, the final recipe is:

- take 16 bytes from offset 0
- take the following 3 bytes: 'fox'
- take 28 byes from offset 20

## The result
For testing we have used 1024 byte blocks and encoded all kernel tar balls
from the "kernel-vanilla" packages of all projects on the reference server. That
meant we needed to encode 2525 tar balls consisting of 207GB of data (1194 GB
convert to uncompressed cpio balls).

Our delta algorithm took each cpio file and converted it to instruction files
plus data added to the delta store. The instruction files sum up to 3.6GB whereas
our delta store is 4.7GB (after compression). So in total we use 8.3 GB, which
only 4% (!!!) of the original compressed tar balls.

Pretty significant storage reduction and cool new ways to interact with git. We
are excited about these changes.  What do you think?  Are you going to make use of
this once it's released? Let us know in the comments!
